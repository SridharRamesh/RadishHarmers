<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!-- This page was generated from TweetParser. -->
<link rel="stylesheet" href="../../styles.css">
</head>
<body>
These are all the tweets and replies that I made on 2020-5-2
<hr>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Consider first y^(n - 1)/(1 + y)^n, for fixed n. At what value of y is this maximized? Taking its derivative, we get (n - 1 - y)y^(n - 2)/(1 + y)^n, which is zero when y = n - 1. Thus, it is maximized at y = n - 1, making its maximum value (n - 1)^(n - 1)/n^n.</p></blockquote>
<br>
Timestamp: 2020-5-2 0:56:4
<br>
Id: 1256386943635599362
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Next, since y^k is an increasing function of k, this tells us y^k/(1 + y)^n is &amp;lt;= (n - 1)^(n - 1)/n^n, when we restrict k to natural numbers less than n.</p></blockquote>
<br>
Timestamp: 2020-5-2 0:56:56
<br>
Id: 1256387159428300800
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Finally, if we replace y with (y/x), and then multiply both sides by x^n, we get the inequality as stated.</p></blockquote>
<br>
Timestamp: 2020-5-2 0:57:45
<br>
Id: 1256387369030365184
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@blackmilosevic @hobartmariner @nntaleb Yes, good catch, I should&#39;ve spelled this out.</p></blockquote>
<br>
Timestamp: 2020-5-2 1:11:55
<br>
Id: 1256390932829745152
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Typos in the above (alas, Twitter has no editing for these little things):<br><br>Where I wrote a derivative of &quot;(n - 1 - y)y^(n - 2)/(1 + y)^n&quot;, the last exponent should have been n + 1.<br><br>When I wrote &quot;multiply both sides&quot;, I meant &quot;multiply numerator and denominator&quot;.</p></blockquote>
<br>
Timestamp: 2020-5-2 1:12:46
<br>
Id: 1256391145443164161
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic The original reasoning presumes y is at least 1. After y is replaced with y/x, this becomes the presumption that y is at least x, and we can always swap x and y to achieve this without loss of generality.</p></blockquote>
<br>
Timestamp: 2020-5-2 1:13:23
<br>
Id: 1256391300334653442
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic But a better conceptual approach that illustrates further generality is this:<br><br>The left hand side is invariant under rescaling x and y by the same factor, so let us rescale them to make x + y = n. Then the inequality is equivalent to showing that y^k x^(n - k) â‰¤ (n - 1)^(n - 1).</p></blockquote>
<br>
Timestamp: 2020-5-2 2:12:27
<br>
Id: 1256406167967932417
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic We&#39;ll show more generally how to optimize x^j y^k when x + y is constrained to a constant and j + k is also constrained to a constant. From this, we&#39;ll know how to bound the expression in question.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:12:35
<br>
Id: 1256406197772660738
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Note that the x and y derivatives of x^j y^k are this expression times j/x and times k/y, respectively. These must be equal if we&#39;re to optimize this expression while x + y is constrained to a constant. Thus, x and y must be in the same ratio as j and k.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:12:45
<br>
Id: 1256406241607323648
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic Thus, we are optimizing an expression proportional to j^j k^k, with j + k constrained to a constant.<br><br>This is an exponential function applied to the Shannon entropy of a probability distribution with probabilities proportional to j and k.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:13:2
<br>
Id: 1256406312864428032
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic And Shannon entropy famously is maximized by making j and k as far apart as possible.<br><br>In our case, j and k are constrained to be positive integers which sum to n, so they are made as far apart as possible by setting one to 1 and the other to n - 1.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:13:29
<br>
Id: 1256406427876372480
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic As we saw that x and y must be in the same ratio as j and k, and we constrained them to have the same sum n, we find that x and y must take the same values 1 and n - 1 accordingly.<br><br>Thus, our maximum achievable value is 1^1 * (n - 1)^(n - 1), which is what we sought to show. QED.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:14:18
<br>
Id: 1256406630352240642
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic I&#39;m sure there are a bunch of innocuous typos in the above which I will not bother to correct.</p></blockquote>
<br>
Timestamp: 2020-5-2 2:15:45
<br>
Id: 1256406995407601675
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@nntaleb @blackmilosevic [I guess the one clarification to say is that in the line &quot;And Shannon entropy famously is maximized by making j and k as far apart as possible&quot;, people normally think of this as minimization, using a differing convention about bases being above or below 1, but whatever.]</p></blockquote>
<br>
Timestamp: 2020-5-2 2:22:18
<br>
Id: 1256408646277349376
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">They say child molesters have it bad in prison, but that&#39;s nothing compared to how other criminals are treated. The infamous Boston Prisoner Strangler did not fare long in lockup before being viciously strangled by prisoners, who are notoriously hostile to prisoner stranglers.</p></blockquote>
<br>
Timestamp: 2020-5-2 3:30:35
<br>
Id: 1256425828260425729
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">All my most cherished memories, I don&#39;t even remember the thing anymore. I just know facts of my history, and pretend memory of memory is memory. Lifelong games of self-telephone. This is bullshit. I might as well be granted knowledge of future events, at this level of sharpness.</p></blockquote>
<br>
Timestamp: 2020-5-2 4:49:57
<br>
Id: 1256445801779408897
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I only have two interests. My life is so short of joy. If I only had one interest, I&#39;d be twice as good at it. Best in the world. My life would be amazing.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:0:57
<br>
Id: 1256448568686268421
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@silvascientist I&#39;m halfway there.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:3:52
<br>
Id: 1256449302647488513
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@raktagulikaa @nntaleb For what it&#39;s worth, the last inequality here is a standard inequality as well. Letting p = k/n, q = 1 - p, and taking the negated logarithm of the left-hand side, it is the Shannon entropy of a {p, q} Bernoulli variable.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:15:19
<br>
Id: 1256452183966601216
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@raktagulikaa @nntaleb A standard result is that this entropy decreases as p and q move further apart. The furthest apart we&#39;ve allowed ourselves to make the two exponents is 1 and n - 1, so the value in this case bounds all others.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:16:42
<br>
Id: 1256452532437692422
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Tearing myself a new one, so I can get out of the bathroom in half the time.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:29:8
<br>
Id: 1256455662600626177
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Each day, oscillating between highs and lows, optimism and pessimism, I have my moments of clarity, but no oracle to confirm for me which they were, no manifest distinction from their opposites. I look back later and still don&#39;t know which moods to trust.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:31:41
<br>
Id: 1256456305780424713
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I regret not doing things ten years ago which I&#39;m not doing currently either, all the better to continue regretting ten years hence.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:36:59
<br>
Id: 1256457639934021632
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">You only get so much time in life. We all die some day. This is why I studiously avoid building up accomplishments and goodwill, so it won&#39;t be so sad when it happens.</p></blockquote>
<br>
Timestamp: 2020-5-2 5:41:45
<br>
Id: 1256458838703833088
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Tearing myself a new one (my eyes off of the computer screen for once).</p></blockquote>
<br>
Timestamp: 2020-5-2 5:55:11
<br>
Id: 1256462216632696832
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I&#39;m trying to get better about receiving compliments. That is, I&#39;m trying to receive more compliments.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:21:6
<br>
Id: 1256649935568752646
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Don&#39;t worry. They&#39;re called murder hornets because of how notoriously easy they are to murder.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:22:9
<br>
Id: 1256650198312517634
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@DoubleEBooks I&#39;m no good at fishing.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:23:0
<br>
Id: 1256650412490399746
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@wcthunderesq I was murdered once as a child, thus developing a lifelong immunity to murder.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:29:29
<br>
Id: 1256652042409566208
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I was murdered once as a child, thus developing a lifelong immunity to murder.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:32:5
<br>
Id: 1256652700676210688
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray Which part?</p></blockquote>
<br>
Timestamp: 2020-5-2 18:33:38
<br>
Id: 1256653089672704002
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray This isn&#39;t all language. This is just the Indo-European language family. Linguists generally don&#39;t find proposals for larger language families to be well-evidenced. But there are very clear systematic correspondences in this particular family.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:37:43
<br>
Id: 1256654117663117317
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray It&#39;s more than &quot;words sound the same&quot;, though. That&#39;s why the linguists reject other crank family theories. It&#39;s very specific falsifiable laws, like Grimm&#39;s Law, that determine how the sounds in one language relate to those in another.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:55:52
<br>
Id: 1256658682059919360
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray The whole point is to look for falsifiable/verifiable such correspondences, and then test them. You can use these to actually predict what the word in one language should be in another, without knowing it ahead of time, and then go test the correctness of the theory.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:57:38
<br>
Id: 1256659129386573824
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray That was the evidence which convinced philologists, the systematic rules of the correspondence, not just random &quot;Oh, lots of these words sound sort of like those words&quot; observations, which I agree would not do it for me either.</p></blockquote>
<br>
Timestamp: 2020-5-2 18:58:23
<br>
Id: 1256659316498726912
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray The evidence for it is as strong and systematic as the evidence that any particular clade of animals derived from a common ancestor. Indeed, historically, it was the success of the linguists&#39; theories which inspired Darwin.</p></blockquote>
<br>
Timestamp: 2020-5-2 19:0:47
<br>
Id: 1256659920100954112
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@zlingray The discovery of the Indo-European language family is historically the reason the Nazis got all hung up on &quot;Aryans&quot; and became fond of swastikas. That did happen. And yet the discovery is correct.</p></blockquote>
<br>
Timestamp: 2020-5-2 19:12:7
<br>
Id: 1256662772684906497
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@imaginary_nums @zlingray @dbweissman Let&#39;s put it this way: there&#39;s no DNA sequencing of languages as such, but the evidence for common descent in biology was understood long before DNA sequencing, or even DNA itself, was discovered.</p></blockquote>
<br>
Timestamp: 2020-5-2 19:22:6
<br>
Id: 1256665284120850434
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@imaginary_nums @zlingray @dbweissman My actual feelings are that the systematic sound shift rules yield more definitive relations than morphology-based clades which can be fooled by parallel/convergent evolution or just focusing too much on a few ostentatious features. But I restrained myself from saying this.</p></blockquote>
<br>
Timestamp: 2020-5-2 20:23:55
<br>
Id: 1256680841662607362
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">@imaginary_nums @zlingray @dbweissman Modern phylogeny does have DNA sequencing, which puts everything else to shame. But we must acknowledge pre-DNA cladistics still generally got a lot right. They were able to soundly recognize apes form a clade including humans, birds are part of the dinosaur clade, etc.</p></blockquote>
<br>
Timestamp: 2020-5-2 20:29:15
<br>
Id: 1256682182791307265
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">STEM stands for Science Theology English and Monkeys. The current consensus among scholars is that it is a polyphyletic grouping, or paraphyletic if monkeys are taken to include apes.</p></blockquote>
<br>
Timestamp: 2020-5-2 20:46:1
<br>
Id: 1256686402571509764
<br>

<hr>

</p>
<p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Biologists are now in consensus that the two major classes of animals are arthrous (for example, the brahminy blind snake or the European legless lizard) and anarthrous (for example, chimpanzees or mice). But it is not yet understood what triggered this evolutionary divergence.</p></blockquote>
<br>
Timestamp: 2020-5-2 20:58:26
<br>
Id: 1256689530721251330
<br>

<hr>

</p>
</body>
</html>
