<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!-- This page was generated from TweetParser. -->
This is the page for date: 2020-11-28 with tweets: 
<p>
Id: 1332474553709322246
<br>
Text: @darth_erogenous You're a cartoonist now, on top of everything else? Leave some skills for the rest of us.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332505636538634248
<br>
Text: @sigfpe I must grant that that town population fit is amazing.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332506917390872576
<br>
Text: @sigfpe I have discovered https://t.co/wToymgJPng, for more of this sort of thing.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332509592102821889
<br>
Text: @sigfpe Out of curiosity, if it's easy to do so, what do these look like if you graph the full histogram of log(X) instead of just the leading digit of X?
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332510610941227008
<br>
Text: @sigfpe It appears that population of US towns is in there already, as is population of UK towns. The fit for US towns is great, the fit for UK towns less so.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332543528619171851
<br>
Text: @sigfpe It's conversely odd to me to say that spanning many orders of magnitude explains a Benford distribution, but whatever.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332543937177939968
<br>
Text: @sigfpe You get a Benfordy distribution for any X = YW with Y and W nearly independent and W nearly log-uniform over a large range (or a range nearly a power of 10), so all that's needed is one such log-uniformish factor. I wonder what that might be for US town population.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332548600870674433
<br>
Text: It has been over a month since my last good post. Sources say I don't have it in me anymore. People have stopped liking me (me, not my posts) in droves.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332740537649127426
<br>
Text: @JoeMoviegoer @sigfpe This only indicates that if log (X) happens to be relatively uniformly distributed over a large range, then Benford's property nearly holds. But why should log (X) happen to be relatively uniformly distributed over a large range?
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332741153121300481
<br>
Text: @JoeMoviegoer @sigfpe Well, for some things this happens of course, and for some things it doesn't. It's one possible distribution, to be log-uniform over a large interval.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332742525833121793
<br>
Text: @JoeMoviegoer @sigfpe That is, something could easily span many orders of magnitude without being specifically log-uniform over that range. Lots of things do that too.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332775505758744577
<br>
Text: I construct a rectangle of 16 dots by 24 dots in my mind, then count 1, 2, 3, 4, 5, etc, till reaching 384. https://t.co/WNh3YwzGo7
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810988966567937
<br>
Text: In case it wasn't clear exactly what we did, we turned (ax + b) * (cx + d) into Ex^2 + Fx + G, where E = a * c, G = b * d, and F =  E + G - (b - a) * (d - c). The x is our base ten, and the a, b, c, and d are the digits of the numbers we start with.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810987804766220
<br>
Text: This is called Karatsuba multiplication, and I'm not joking when I say it was a major breakthrough. Ordinarily, to multiply a pair of two-digit numbers, you have to do four single-digit multiplications. Here, we got away with three single-digit multiplications.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810986718425091
<br>
Text: Historically, it was a major breakthrough in mathematics, discovered in the 1960s, to recognize that this could be tackled like so:

1 * 2 = Two
6 * 4 = Twenty-four
Two + Twenty-four - (6 - 1) * (4 - 2) = Sixteen

So the answer is Two hundred + Sixteen tens + Twenty-Four = 384.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810993286717441
<br>
Text: Andrey Kolmogorov, a major mathematician, conjectured in 1960 that the N^2 was as good as it gets, but then his student Anatoly Karatsuba discovered this, the first time in history anyone realized how to multiply long numbers more efficiently than the elementary school way.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810992376553480
<br>
Text: (Plus some addition and subtraction steps, but not much more of those in either method, on top of the single-digit multiplication steps. It's often reasonable to gauge the overall time taken by just looking at the number of single-digit multiplication steps.)
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810991139164161
<br>
Text: When multiplying two N-digit numbers, the familiar elementary school method requires N^2 many single-digit multiplications, while this iterated Karatsuba method gets away with essentially N^(log(3)/log(2))) â‰ˆ N^1.58 many single-digit multiplication steps.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810989809643521
<br>
Text: Even for numbers with more than two digits, we can use this same Karatsuba idea to turn multiplying a pair of long numbers into three multiplications of numbers with half as many digits. And then turn each of those into three multiplications of quarter-length numbers, and so on.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810997946527744
<br>
Text: These later ideas are not so much harder than Karatsuba's idea to explain either, but I know no one cares after the first few posts of a thread like this. They're also only really a win for very long numbers, because they increase the overhead of the addition etc steps a bit.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810997128687623
<br>
Text: Like everyone one-upping each other's speed records right after Bannister proved the sub-four minute mile possible at all.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810995832680450
<br>
Text: And then people realized how to connect this to the Fast Fourier Transform to make it even more efficient, on the order of N log(N) many single-digit multiplication steps.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332810994540814336
<br>
Text: That's not the end of the story, though. Shortly after that, yet another Russian, Andrei Toom, realized how to generalize Karatsuba's idea to become even more efficient, bringing the exponent in N^(log(3)/log(2)) down to log(2k - 1)/log(k), which gets as close to 1 as you like.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332816759422902275
<br>
Text: @JoeMoviegoer @sigfpe Yes, and keep in mind, it can't be that a population of 10 and a population of 10^5 have the same frequency, but rather, it needs to be that 10 is about ten thousand times as frequent as 10^5, in keeping with [10, 11) being ten thousand times smaller than [10^5, 1.1 * 10^5).
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332817691636273152
<br>
Text: @JoeMoviegoer @sigfpe Perhaps we are simply not inclined to say of distributions that they "span many orders of magnitude" unless it feels like they assign about a uniform probability to each order of magnitude, making them log-uniform.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332817753263251457
<br>
Text: @JoeMoviegoer @sigfpe So that even a uniform distribution from 1 to a trillion is not the sort of thing that one is naturally inclined to say "spans many orders of magnitude", since 90% of the distribution has twelve digits and only 10% of it is smaller.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332823077256900612
<br>
Text: @db_Math I never know good references for anything, but honestly, I think you could pick up the key ideas from Wikipedia, though it takes some skill to know how to find the key idea in a Wikipedia math article instead of being distracted by everything else.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332824151929839624
<br>
Text: @db_Math See https://t.co/hs9KmMON7S in general and see https://t.co/yQ6GXq0Y6K for Toom's method in particular. The Wikipedia writeups on Fast Fourier Transform approaches bog down the key ideas a bit more with very particular details, but perhaps you really want those details.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332835660995104776
<br>
Text: @mirrorsaw_ Biden won. We achieved our goal and must move on to something else.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332836117356359680
<br>
Text: I'm all out of post ideas, so this is the slop you pigs get.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332836116387536898
<br>
Text: Numbers come up a lot because numbers happen to be ubiquitously useful, but math is about whatever. Alas, my merely saying "math is about whatever" is not very useful for conveying what I mean by that. C'est la vie, some other time I'll say something else better.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332836115401814018
<br>
Text: Which is fine, but I fear I am in so doing contributing to everyone's mistaken impression as to what math is about, the general impression that math is specifically about numbers and numbery things and maybe some geometry.
<br>
Created at: 2020-11-28
<br>
----
</p>
<p>
Id: 1332836114466541568
<br>
Text: Relatively little of the times when I discuss math on here involve me discussing my ostensible specialization (logic), they're usually on some arithmetic thing instead. They could be about a million things but usually end up being about that, because that's what someone prompts.
<br>
Created at: 2020-11-28
<br>
----
</p>
</head>
</html>
